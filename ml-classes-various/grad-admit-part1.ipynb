{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admit_raw = pd.read_csv(\"Admission_Predict_Ver1.1.csv\")\n",
    "admit_x = admit_raw[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research']]\n",
    "admit_y = admit_raw['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
      "0        337          118                  4  4.5   4.5  9.65         1\n",
      "1        324          107                  4  4.0   4.5  8.87         1\n",
      "2        316          104                  3  3.0   3.5  8.00         1\n",
      "3        322          110                  3  3.5   2.5  8.67         1\n",
      "4        314          103                  2  2.0   3.0  8.21         0\n"
     ]
    }
   ],
   "source": [
    "print(admit_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_trn, x_tst, y_trn, y_tst = model_selection.train_test_split(admit_x, admit_y, test_size=0.20, random_state=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "admit_x_scale = scaler.fit_transform(admit_x)\n",
    "x_trn_scale = scaler.fit_transform(x_trn)\n",
    "x_tst_scale = scaler.fit_transform(x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 1\n",
      "Explained Variance 4.74\n",
      "[-0.40361694 -0.40120339 -0.3834133  -0.38466158 -0.3471675  -0.42103736\n",
      " -0.28872336]\n",
      "Component 2\n",
      "Explained Variance 0.74\n",
      "[-0.27452263 -0.11081202  0.2497745   0.3434338   0.42602733 -0.01504455\n",
      " -0.74182095]\n",
      "Component 3\n",
      "Explained Variance 0.56\n",
      "[-0.36263743 -0.46108277  0.09291061  0.17312554  0.46450082 -0.24073704\n",
      "  0.58615408]\n",
      "Component 4\n",
      "Explained Variance 0.38\n",
      "[-0.14482269 -0.12684268  0.64173368  0.32685429 -0.64859464 -0.13665843\n",
      "  0.07022078]\n",
      "Component 5\n",
      "Explained Variance 0.26\n",
      "[ 0.04779188 -0.03008301  0.60698049 -0.76276584  0.21111694 -0.01945709\n",
      " -0.04031081]\n",
      "Component 6\n",
      "Explained Variance 0.18\n",
      "[-0.25090997  0.72652707  0.03207901  0.01981706  0.09562054 -0.62726591\n",
      "  0.07193756]\n",
      "Component 7\n",
      "Explained Variance 0.15\n",
      "[ 0.73757122 -0.2632937   0.02642093  0.12279282  0.08846344 -0.59332137\n",
      " -0.10503789]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 7)\n",
    "pca.fit(admit_x_scale)\n",
    "\n",
    "for i in range(7):\n",
    "    print(\"Component %d\" % (i+1))\n",
    "    print(\"Explained Variance %.2f\" % pca.explained_variance_[i])\n",
    "    print(pca.components_[i])\n",
    "    plt.clf()\n",
    "    c_scalar = np.matmul(admit_x_scale, pca.components_[i])\n",
    "    plt.xlabel(\"Projection onto Component %d\" % (i+1))\n",
    "    plt.ylabel(\"Admit Prob.\")\n",
    "    plt.plot(c_scalar, admit_y, 'o')\n",
    "    plt.savefig(\"images/proj_component_%d.png\" % (i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 components:\n",
      "Coef: [-0.05576297]\n",
      "Intercept 0.727125\n",
      "R^2: 0.78\n",
      "Test MSE: 0.0062\n",
      "[0.02248775 0.02244954 0.02155522 0.02174614 0.01929519 0.02358981\n",
      " 0.01528144]\n",
      "\n",
      "Using 2 components:\n",
      "Coef: [-0.05576297 -0.00414248]\n",
      "Intercept 0.727125\n",
      "R^2: 0.78\n",
      "Test MSE: 0.0060\n",
      "[0.02350679 0.02265821 0.02069285 0.02048776 0.01770937 0.02349438\n",
      " 0.01863212]\n",
      "\n",
      "Using 3 components:\n",
      "Coef: [-0.05576297 -0.00414248 -0.01550427]\n",
      "Intercept 0.727125\n",
      "R^2: 0.79\n",
      "Test MSE: 0.0058\n",
      "[0.02980593 0.02976151 0.01850598 0.01729205 0.0098336  0.02713291\n",
      " 0.01088714]\n",
      "\n",
      "Using 4 components:\n",
      "Coef: [-0.05576297 -0.00414248 -0.01550427 -0.01768428]\n",
      "Intercept 0.727125\n",
      "R^2: 0.80\n",
      "Test MSE: 0.0056\n",
      "[0.03209665 0.03226206 0.00720525 0.01119189 0.02123653 0.02957133\n",
      " 0.01030158]\n",
      "\n",
      "Using 5 components:\n",
      "Coef: [-0.05576297 -0.00414248 -0.01550427 -0.01768428  0.00397417]\n",
      "Intercept 0.727125\n",
      "R^2: 0.80\n",
      "Test MSE: 0.0056\n",
      "[0.03254699 0.03214769 0.0096451  0.00823477 0.02207263 0.02921066\n",
      " 0.01007454]\n",
      "\n",
      "Using 6 components:\n",
      "Coef: [-0.05576297 -0.00414248 -0.01550427 -0.01768428  0.00397417 -0.03423429]\n",
      "Intercept 0.727125\n",
      "R^2: 0.81\n",
      "Test MSE: 0.0054\n",
      "[0.0418919  0.00688166 0.00880693 0.00691432 0.01962673 0.04998024\n",
      " 0.00752831]\n",
      "\n",
      "Using 7 components:\n",
      "Coef: [-0.05576297 -0.00414248 -0.01550427 -0.01768428  0.00397417 -0.03423429\n",
      " -0.03118393]\n",
      "Intercept 0.727125\n",
      "R^2: 0.82\n",
      "Test MSE: 0.0052\n",
      "[0.01967332 0.01451809 0.01000954 0.00075494 0.01642515 0.06895161\n",
      " 0.01083138]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using linear regression on PCA (1-7 components)\n",
    "\n",
    "for i in range(7):\n",
    "    print(\"Using %d components:\" % (i+1))\n",
    "    \n",
    "    pca = PCA(n_components = i+1)\n",
    "    x_trn_pca = pca.fit_transform(x_trn_scale)\n",
    "    x_tst_pca = pca.transform(x_tst_scale)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_trn_pca, y_trn)\n",
    "    print(\"Coef: %s\" % lr.coef_)\n",
    "    print(\"Intercept %s\" % lr.intercept_)\n",
    "    print(\"R^2: %.2f\" % lr.score(x_trn_pca, y_trn))\n",
    "    print(\"Test MSE: %.4f\" % np.mean(np.square(y_tst - lr.predict(x_tst_pca))))\n",
    "    print(np.matmul(lr.coef_, pca.components_))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classficiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "admit_y_cls = (admit_y > np.median(admit_y)) * 1\n",
    "y_trn_cls = (y_trn > np.median(admit_y)) * 1\n",
    "y_tst_cls = (y_tst > np.median(admit_y)) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 components:\n",
      "Coef: [[-1.61256334]]\n",
      "Test Accuracy: 0.8900\n",
      "\n",
      "Using 2 components:\n",
      "Coef: [[-1.60772479 -0.3037459 ]]\n",
      "Test Accuracy: 0.8600\n",
      "\n",
      "Using 3 components:\n",
      "Coef: [[-1.62694271 -0.31067103 -0.22893158]]\n",
      "Test Accuracy: 0.8800\n",
      "\n",
      "Using 4 components:\n",
      "Coef: [[-1.63517069 -0.31521748 -0.23285306 -0.28575366]]\n",
      "Test Accuracy: 0.8800\n",
      "\n",
      "Using 5 components:\n",
      "Coef: [[-1.63416499 -0.31589112 -0.23275488 -0.28438636 -0.06506967]]\n",
      "Test Accuracy: 0.8700\n",
      "\n",
      "Using 6 components:\n",
      "Coef: [[-1.67174558 -0.34744008 -0.25612129 -0.2024366  -0.13403168 -1.03345872]]\n",
      "Test Accuracy: 0.8700\n",
      "\n",
      "Using 7 components:\n",
      "Coef: [[-1.68665131 -0.35401632 -0.24543345 -0.18486214 -0.13878989 -1.03612143\n",
      "  -0.39717803]]\n",
      "Test Accuracy: 0.8800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Adam Chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Using logistic regression on PCA (1-7 components)\n",
    "\n",
    "for i in range(7):\n",
    "    print(\"Using %d components:\" % (i+1))\n",
    "    \n",
    "    pca = PCA(n_components = i+1)\n",
    "    x_trn_pca = pca.fit_transform(x_trn_scale)\n",
    "    x_tst_pca = pca.transform(x_tst_scale)\n",
    "\n",
    "    logr = LogisticRegression()\n",
    "    logr.fit(x_trn_pca, y_trn_cls)\n",
    "    print(\"Coef: %s\" % logr.coef_)\n",
    "    print(\"Test Accuracy: %.4f\" % (np.sum(y_tst_cls == logr.predict(x_tst_pca)) / len(y_tst_cls)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "admit_x_pca = pca.fit_transform(admit_x_scale)\n",
    "plt.plot(admit_x_pca[admit_y > np.median(admit_y)][:,0], admit_x_pca[admit_y > np.median(admit_y)][:,1], 'o', label = 'Top')\n",
    "plt.plot(admit_x_pca[admit_y <= np.median(admit_y)][:,0], admit_x_pca[admit_y <= np.median(admit_y)][:,1], 'o', label = 'Bottom')\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/c1c2.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "admit_x_pca = pca.fit_transform(admit_x_scale)\n",
    "plt.plot(admit_x_pca[admit_y > np.median(admit_y)][:,0], admit_x_pca[admit_y > np.median(admit_y)][:,2], 'o', label = 'Top')\n",
    "plt.plot(admit_x_pca[admit_y <= np.median(admit_y)][:,0], admit_x_pca[admit_y <= np.median(admit_y)][:,2], 'o', label = 'Bottom')\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 3\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/c1c3.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "admit_x_pca = pca.fit_transform(admit_x_scale)\n",
    "plt.plot(admit_x_pca[admit_y > np.median(admit_y)][:,1], admit_x_pca[admit_y > np.median(admit_y)][:,2], 'o', label = 'Top')\n",
    "plt.plot(admit_x_pca[admit_y <= np.median(admit_y)][:,1], admit_x_pca[admit_y <= np.median(admit_y)][:,2], 'o', label = 'Bottom')\n",
    "plt.xlabel(\"Component 2\")\n",
    "plt.ylabel(\"Component 3\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/c2c3.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "for nc in [2, 3, 6, 10]:\n",
    "    km = KMeans(n_clusters = nc)\n",
    "    km.fit(x_trn_scale)\n",
    "    \n",
    "    for i in range(nc):\n",
    "        cluster_y = y_trn[km.labels_ == i]\n",
    "        plt.clf()\n",
    "        plt.title(\"K-Means (n = %d) - Cluster %d\" % (nc, i))\n",
    "        plt.hist(cluster_y)\n",
    "        plt.savefig(\"images/km_n%d_c%d.png\" % (nc, i))\n",
    "    print(\"==========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Clusters MSE: 0.0190\n",
      "2 Clusters MSE: 0.0190\n",
      "3 Clusters MSE: 0.0192\n",
      "4 Clusters MSE: 0.0192\n",
      "5 Clusters MSE: 0.0194\n",
      "6 Clusters MSE: 0.0198\n",
      "7 Clusters MSE: 0.0197\n",
      "8 Clusters MSE: 0.0196\n",
      "9 Clusters MSE: 0.0197\n",
      "10 Clusters MSE: 0.0198\n",
      "11 Clusters MSE: 0.0197\n",
      "12 Clusters MSE: 0.0200\n",
      "13 Clusters MSE: 0.0199\n",
      "14 Clusters MSE: 0.0201\n",
      "15 Clusters MSE: 0.0201\n",
      "16 Clusters MSE: 0.0201\n",
      "17 Clusters MSE: 0.0211\n",
      "18 Clusters MSE: 0.0207\n",
      "19 Clusters MSE: 0.0204\n",
      "20 Clusters MSE: 0.0204\n"
     ]
    }
   ],
   "source": [
    "for nc in range(1,21):\n",
    "    km = KMeans(n_clusters = nc)\n",
    "    mses = []\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=350)\n",
    "    \n",
    "    for train_index, test_index in kf.split(x_trn_scale):\n",
    "        km.fit(x_trn_scale[train_index])\n",
    "\n",
    "        km_pred = km.predict(x_trn_scale[test_index])\n",
    "        y_pred = np.zeros(len(test_index))        \n",
    "\n",
    "        for i in range(len(test_index)):\n",
    "            y_pred[i] = np.mean(y_trn[train_index][km.labels_ == km_pred[i]])\n",
    "            \n",
    "        mses.append(np.mean(np.square(y_trn[test_index] - y_pred)))\n",
    "\n",
    "    print(\"%d Clusters MSE: %0.4f\" % (nc, np.mean(mses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0075672731548239325\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters = 6)\n",
    "km.fit(x_trn_scale)\n",
    "\n",
    "km_pred = km.predict(x_tst_scale)\n",
    "y_pred = np.zeros(len(y_tst))\n",
    "\n",
    "for i in range(len(y_tst)):\n",
    "    y_pred[i] = np.mean(y_trn[km.labels_ == km_pred[i]])\n",
    "            \n",
    "print(np.mean(np.square(y_tst - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters = 6)\n",
    "km.fit(x_trn_scale)\n",
    "\n",
    "km_pred = km.predict(x_tst_scale)\n",
    "y_pred = np.zeros(len(y_tst_cls))\n",
    "\n",
    "for i in range(len(y_tst)):\n",
    "    y_pred[i] = stats.mode(y_trn_cls[km.labels_ == km_pred[i]])[0]\n",
    "            \n",
    "print(np.sum(y_pred == y_tst_cls) / len(y_tst_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
